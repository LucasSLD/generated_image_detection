\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{nty/global//global/global}
\abx@aux@cite{0}{goodfellowGenerativeAdversarialNetworks2014}
\abx@aux@segm{0}{0}{goodfellowGenerativeAdversarialNetworks2014}
\@writefile{tdo}{\contentsline {todo}{develop on the team environment (saw a phd defense, sigma day)}{3}{section*.3}\protected@file@percent }
\pgfsyspdfmark {pgfid1}{19562754}{36768330}
\abx@aux@cite{0}{tariangSyntheticImageVerification2024}
\abx@aux@segm{0}{0}{tariangSyntheticImageVerification2024}
\@writefile{toc}{\contentsline {section}{\numberline {1}AI-generated images detection}{4}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}AI image generation}{4}{subsection.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces GAN architecture}}{4}{figure.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{More on diffusion model}{4}{section*.4}\protected@file@percent }
\pgfsyspdfmark {pgfid2}{19562754}{16469052}
\abx@aux@cite{0}{tariangSyntheticImageVerification2024}
\abx@aux@segm{0}{0}{tariangSyntheticImageVerification2024}
\abx@aux@cite{0}{tariangSyntheticImageVerification2024}
\abx@aux@segm{0}{0}{tariangSyntheticImageVerification2024}
\abx@aux@cite{0}{cozzolinoRaisingBarAIgenerated2024}
\abx@aux@segm{0}{0}{cozzolinoRaisingBarAIgenerated2024}
\abx@aux@cite{0}{cozzolinoRaisingBarAIgenerated2024}
\abx@aux@segm{0}{0}{cozzolinoRaisingBarAIgenerated2024}
\abx@aux@cite{0}{radfordLearningTransferableVisual2021}
\abx@aux@segm{0}{0}{radfordLearningTransferableVisual2021}
\abx@aux@cite{0}{tianContrastiveMultiviewCoding2020}
\abx@aux@segm{0}{0}{tianContrastiveMultiviewCoding2020}
\abx@aux@cite{0}{radfordLearningTransferableVisual2021}
\abx@aux@segm{0}{0}{radfordLearningTransferableVisual2021}
\abx@aux@cite{0}{radfordLearningTransferableVisual2021}
\abx@aux@segm{0}{0}{radfordLearningTransferableVisual2021}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Detection based on high-level artifacts}{5}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Detection based on low-level artifacts}{5}{subsection.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Figure and caption extracted from \blx@tocontentsinit {0}\autocite *{tariangSyntheticImageVerification2024}. Top: examples of synthetic images, generated using (from left to right) Latent Diffusion, Stable Diffusion, Midjourney v5, DALL·E Mini, DALL·E 2, DALL·E 3. The prompt used for their generation is the following: a photo of the Rome Colosseum with a UFO over it, detailed, 8k. Bottom: Average Power Spectra of the artificial fingerprints for each of such model. Forensic artifacts are clearly visible as spectral peaks in the Fourier domain, stronger or weaker based on the specific model. We can observe that the first three images share very similar artifacts while the fingerprints of the three releases of DALL-E differ greatly from one another, testifying to very different generative architectures.}}{5}{figure.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Data-driven approaches}{6}{subsection.1.4}\protected@file@percent }
\abx@aux@cite{0}{oquabDINOv2LearningRobust2024}
\abx@aux@segm{0}{0}{oquabDINOv2LearningRobust2024}
\abx@aux@cite{0}{khanCLIPpingDeceptionAdapting2024}
\abx@aux@segm{0}{0}{khanCLIPpingDeceptionAdapting2024}
\abx@aux@cite{0}{zhangTipAdapterTrainingfreeAdaption2022}
\abx@aux@segm{0}{0}{zhangTipAdapterTrainingfreeAdaption2022}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Figure from \blx@tocontentsinit {0}\autocite *{radfordLearningTransferableVisual2021}. Images and text are embedded in a latent space, the cosine similarity is then computed on pairs of texts and images.}}{7}{figure.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Contributions and associated results}{7}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Impact of JPEG compression}{7}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Adding diversity to the data}{7}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Bigger datasets and neural network}{7}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Pair training}{7}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Filling the holes with fine tuning}{7}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Color features}{7}{subsection.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}DINO as an alternative to CLIP}{7}{subsection.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Tip-Adapter}{7}{subsection.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Conclusion and perspectives}{8}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Understanding CLIP features}{8}{subsection.3.1}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{7305A9DB1A77118E3508D1AC077F7F48}
\abx@aux@defaultrefcontext{0}{cozzolinoRaisingBarAIgenerated2024}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{goodfellowGenerativeAdversarialNetworks2014}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{khanCLIPpingDeceptionAdapting2024}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{oquabDINOv2LearningRobust2024}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{radfordLearningTransferableVisual2021}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{tariangSyntheticImageVerification2024}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{tianContrastiveMultiviewCoding2020}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{zhangTipAdapterTrainingfreeAdaption2022}{nty/global//global/global}
\gdef \@abspage@last{9}
