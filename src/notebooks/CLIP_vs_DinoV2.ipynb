{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lsaland/micromamba/envs/clip/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/lsaland/micromamba/envs/clip/lib/python3.11/site-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
      "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 11.06it/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../model/\")\n",
    "sys.path.append(\"../tools/\")\n",
    "from constants import *\n",
    "from MLP_classifier import MultiClassClassifier\n",
    "from dataset import FlickrAndPairs, TaskA, TaskAWithLabel, SimpleDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3333/3333 [00:00<00:00, 4989.15it/s]\n",
      "100%|██████████| 3333/3333 [00:00<00:00, 4935.96it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_dino = FlickrAndPairs(path=\"/data4/saland/data/flickr_and_pairs_DinoV2.pt\",load_from_disk=True)\n",
    "train_data_clip = FlickrAndPairs(path=\"/data4/saland/data/flickr_and_pairs.pt\",load_from_disk=True)\n",
    "test_data_dino  = TaskAWithLabel(path_to_csv=\"../../docs/scan.csv\",path_to_taskA=\"/data4/saland/data/taskA_dinoV2.pt\")\n",
    "test_data_clip  = TaskAWithLabel(path_to_csv=\"../../docs/scan.csv\",path_to_taskA=\"/data4/saland/data/taskA.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIP vs DINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "model_dino = MultiClassClassifier(n_features=DINO_FEATURE_DIM,n_classes=2).to(device)\n",
    "model_clip = MultiClassClassifier(n_features=CLIP_FEATURE_DIM,n_classes=2).to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "n_epochs = 1000\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer_clip = torch.optim.SGD(model_clip.parameters(), lr=lr)\n",
    "optimizer_dino = torch.optim.SGD(model_dino.parameters(), lr=lr)\n",
    "model_dino.train()\n",
    "model_clip.train()\n",
    "\n",
    "rng = torch.Generator().manual_seed(SEED)\n",
    "\n",
    "train_loader_dino = DataLoader(train_data_dino,batch_size=batch_size,shuffle=True,generator=rng)\n",
    "train_loader_clip = DataLoader(train_data_clip,batch_size=batch_size,shuffle=True,generator=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_dino: 0.559759 [   10/ 1000]\n",
      "loss_dino: 0.488277 [   20/ 1000]\n",
      "loss_dino: 0.309040 [   30/ 1000]\n",
      "loss_dino: 0.295351 [   40/ 1000]\n",
      "loss_dino: 0.287999 [   50/ 1000]\n",
      "loss_dino: 0.141933 [   60/ 1000]\n",
      "loss_dino: 0.193949 [   70/ 1000]\n",
      "loss_dino: 0.131623 [   80/ 1000]\n",
      "loss_dino: 0.099305 [   90/ 1000]\n",
      "loss_dino: 0.062152 [  100/ 1000]\n",
      "loss_dino: 0.108954 [  110/ 1000]\n",
      "loss_dino: 0.072467 [  120/ 1000]\n",
      "loss_dino: 0.078572 [  130/ 1000]\n",
      "loss_dino: 0.075661 [  140/ 1000]\n",
      "loss_dino: 0.071094 [  150/ 1000]\n",
      "loss_dino: 0.087684 [  160/ 1000]\n",
      "loss_dino: 0.073516 [  170/ 1000]\n",
      "loss_dino: 0.057642 [  180/ 1000]\n",
      "loss_dino: 0.057338 [  190/ 1000]\n",
      "loss_dino: 0.073112 [  200/ 1000]\n",
      "loss_dino: 0.043730 [  210/ 1000]\n",
      "loss_dino: 0.041186 [  220/ 1000]\n",
      "loss_dino: 0.031449 [  230/ 1000]\n",
      "loss_dino: 0.048077 [  240/ 1000]\n",
      "loss_dino: 0.037844 [  250/ 1000]\n",
      "loss_dino: 0.030416 [  260/ 1000]\n",
      "loss_dino: 0.033182 [  270/ 1000]\n",
      "loss_dino: 0.018958 [  280/ 1000]\n",
      "loss_dino: 0.017487 [  290/ 1000]\n",
      "loss_dino: 0.020769 [  300/ 1000]\n",
      "loss_dino: 0.017005 [  310/ 1000]\n",
      "loss_dino: 0.028116 [  320/ 1000]\n",
      "loss_dino: 0.017938 [  330/ 1000]\n",
      "loss_dino: 0.016677 [  340/ 1000]\n",
      "loss_dino: 0.018141 [  350/ 1000]\n",
      "loss_dino: 0.007918 [  360/ 1000]\n",
      "loss_dino: 0.020275 [  370/ 1000]\n",
      "loss_dino: 0.018628 [  380/ 1000]\n",
      "loss_dino: 0.014155 [  390/ 1000]\n",
      "loss_dino: 0.007693 [  400/ 1000]\n",
      "loss_dino: 0.012541 [  410/ 1000]\n",
      "loss_dino: 0.012053 [  420/ 1000]\n",
      "loss_dino: 0.012403 [  430/ 1000]\n",
      "loss_dino: 0.014825 [  440/ 1000]\n",
      "loss_dino: 0.013898 [  450/ 1000]\n",
      "loss_dino: 0.012239 [  460/ 1000]\n",
      "loss_dino: 0.014261 [  470/ 1000]\n",
      "loss_dino: 0.004659 [  480/ 1000]\n",
      "loss_dino: 0.003419 [  490/ 1000]\n",
      "loss_dino: 0.008473 [  500/ 1000]\n",
      "loss_dino: 0.011939 [  510/ 1000]\n",
      "loss_dino: 0.008877 [  520/ 1000]\n",
      "loss_dino: 0.007914 [  530/ 1000]\n",
      "loss_dino: 0.009693 [  540/ 1000]\n",
      "loss_dino: 0.010550 [  550/ 1000]\n",
      "loss_dino: 0.009805 [  560/ 1000]\n",
      "loss_dino: 0.010314 [  570/ 1000]\n",
      "loss_dino: 0.007487 [  580/ 1000]\n",
      "loss_dino: 0.004059 [  590/ 1000]\n",
      "loss_dino: 0.008059 [  600/ 1000]\n",
      "loss_dino: 0.008061 [  610/ 1000]\n",
      "loss_dino: 0.007634 [  620/ 1000]\n",
      "loss_dino: 0.007552 [  630/ 1000]\n",
      "loss_dino: 0.005068 [  640/ 1000]\n",
      "loss_dino: 0.009782 [  650/ 1000]\n",
      "loss_dino: 0.005559 [  660/ 1000]\n",
      "loss_dino: 0.006925 [  670/ 1000]\n",
      "loss_dino: 0.006290 [  680/ 1000]\n",
      "loss_dino: 0.004806 [  690/ 1000]\n",
      "loss_dino: 0.005701 [  700/ 1000]\n",
      "loss_dino: 0.003079 [  710/ 1000]\n",
      "loss_dino: 0.004875 [  720/ 1000]\n",
      "loss_dino: 0.006071 [  730/ 1000]\n",
      "loss_dino: 0.005662 [  740/ 1000]\n",
      "loss_dino: 0.005066 [  750/ 1000]\n",
      "loss_dino: 0.005326 [  760/ 1000]\n",
      "loss_dino: 0.005224 [  770/ 1000]\n",
      "loss_dino: 0.006068 [  780/ 1000]\n",
      "loss_dino: 0.004070 [  790/ 1000]\n",
      "loss_dino: 0.004878 [  800/ 1000]\n",
      "loss_dino: 0.003703 [  810/ 1000]\n",
      "loss_dino: 0.003219 [  820/ 1000]\n",
      "loss_dino: 0.004981 [  830/ 1000]\n",
      "loss_dino: 0.005407 [  840/ 1000]\n",
      "loss_dino: 0.005554 [  850/ 1000]\n",
      "loss_dino: 0.004141 [  860/ 1000]\n",
      "loss_dino: 0.004276 [  870/ 1000]\n",
      "loss_dino: 0.004713 [  880/ 1000]\n",
      "loss_dino: 0.003007 [  890/ 1000]\n",
      "loss_dino: 0.004113 [  900/ 1000]\n",
      "loss_dino: 0.003743 [  910/ 1000]\n",
      "loss_dino: 0.002996 [  920/ 1000]\n",
      "loss_dino: 0.003257 [  930/ 1000]\n",
      "loss_dino: 0.004732 [  940/ 1000]\n",
      "loss_dino: 0.002982 [  950/ 1000]\n",
      "loss_dino: 0.004296 [  960/ 1000]\n",
      "loss_dino: 0.002811 [  970/ 1000]\n",
      "loss_dino: 0.004160 [  980/ 1000]\n",
      "loss_dino: 0.004480 [  990/ 1000]\n",
      "loss_dino: 0.003533 [ 1000/ 1000]\n",
      "loss_dino: 0.336830 [   10/ 1000]\n",
      "loss_dino: 0.180544 [   20/ 1000]\n",
      "loss_dino: 0.220742 [   30/ 1000]\n",
      "loss_dino: 0.186260 [   40/ 1000]\n",
      "loss_dino: 0.227129 [   50/ 1000]\n",
      "loss_dino: 0.232040 [   60/ 1000]\n",
      "loss_dino: 0.102703 [   70/ 1000]\n",
      "loss_dino: 0.328174 [   80/ 1000]\n",
      "loss_dino: 0.095089 [   90/ 1000]\n",
      "loss_dino: 0.097312 [  100/ 1000]\n",
      "loss_dino: 0.036568 [  110/ 1000]\n",
      "loss_dino: 0.052010 [  120/ 1000]\n",
      "loss_dino: 0.160522 [  130/ 1000]\n",
      "loss_dino: 0.062391 [  140/ 1000]\n",
      "loss_dino: 0.082071 [  150/ 1000]\n",
      "loss_dino: 0.064016 [  160/ 1000]\n",
      "loss_dino: 0.057638 [  170/ 1000]\n",
      "loss_dino: 0.131496 [  180/ 1000]\n",
      "loss_dino: 0.154096 [  190/ 1000]\n",
      "loss_dino: 0.094989 [  200/ 1000]\n",
      "loss_dino: 0.065129 [  210/ 1000]\n",
      "loss_dino: 0.060669 [  220/ 1000]\n",
      "loss_dino: 0.118678 [  230/ 1000]\n",
      "loss_dino: 0.130341 [  240/ 1000]\n",
      "loss_dino: 0.106576 [  250/ 1000]\n",
      "loss_dino: 0.038255 [  260/ 1000]\n",
      "loss_dino: 0.143084 [  270/ 1000]\n",
      "loss_dino: 0.077146 [  280/ 1000]\n",
      "loss_dino: 0.091185 [  290/ 1000]\n",
      "loss_dino: 0.072284 [  300/ 1000]\n",
      "loss_dino: 0.039159 [  310/ 1000]\n",
      "loss_dino: 0.066280 [  320/ 1000]\n",
      "loss_dino: 0.112211 [  330/ 1000]\n",
      "loss_dino: 0.221568 [  340/ 1000]\n",
      "loss_dino: 0.053484 [  350/ 1000]\n",
      "loss_dino: 0.043073 [  360/ 1000]\n",
      "loss_dino: 0.031109 [  370/ 1000]\n",
      "loss_dino: 0.042058 [  380/ 1000]\n",
      "loss_dino: 0.086318 [  390/ 1000]\n",
      "loss_dino: 0.022136 [  400/ 1000]\n",
      "loss_dino: 0.214987 [  410/ 1000]\n",
      "loss_dino: 0.018265 [  420/ 1000]\n",
      "loss_dino: 0.055403 [  430/ 1000]\n",
      "loss_dino: 0.052345 [  440/ 1000]\n",
      "loss_dino: 0.071517 [  450/ 1000]\n",
      "loss_dino: 0.111250 [  460/ 1000]\n",
      "loss_dino: 0.060536 [  470/ 1000]\n",
      "loss_dino: 0.054969 [  480/ 1000]\n",
      "loss_dino: 0.011304 [  490/ 1000]\n",
      "loss_dino: 0.027351 [  500/ 1000]\n",
      "loss_dino: 0.049094 [  510/ 1000]\n",
      "loss_dino: 0.028708 [  520/ 1000]\n",
      "loss_dino: 0.016784 [  530/ 1000]\n",
      "loss_dino: 0.083177 [  540/ 1000]\n",
      "loss_dino: 0.024476 [  550/ 1000]\n",
      "loss_dino: 0.081239 [  560/ 1000]\n",
      "loss_dino: 0.049981 [  570/ 1000]\n",
      "loss_dino: 0.057233 [  580/ 1000]\n",
      "loss_dino: 0.008354 [  590/ 1000]\n",
      "loss_dino: 0.047162 [  600/ 1000]\n",
      "loss_dino: 0.012260 [  610/ 1000]\n",
      "loss_dino: 0.021264 [  620/ 1000]\n",
      "loss_dino: 0.015529 [  630/ 1000]\n",
      "loss_dino: 0.061177 [  640/ 1000]\n",
      "loss_dino: 0.075069 [  650/ 1000]\n",
      "loss_dino: 0.006220 [  660/ 1000]\n",
      "loss_dino: 0.061470 [  670/ 1000]\n",
      "loss_dino: 0.036147 [  680/ 1000]\n",
      "loss_dino: 0.025704 [  690/ 1000]\n",
      "loss_dino: 0.009936 [  700/ 1000]\n",
      "loss_dino: 0.010211 [  710/ 1000]\n",
      "loss_dino: 0.034215 [  720/ 1000]\n",
      "loss_dino: 0.110242 [  730/ 1000]\n",
      "loss_dino: 0.016077 [  740/ 1000]\n",
      "loss_dino: 0.030599 [  750/ 1000]\n",
      "loss_dino: 0.021594 [  760/ 1000]\n",
      "loss_dino: 0.037664 [  770/ 1000]\n",
      "loss_dino: 0.068703 [  780/ 1000]\n",
      "loss_dino: 0.031891 [  790/ 1000]\n",
      "loss_dino: 0.029203 [  800/ 1000]\n",
      "loss_dino: 0.039377 [  810/ 1000]\n",
      "loss_dino: 0.031821 [  820/ 1000]\n",
      "loss_dino: 0.046239 [  830/ 1000]\n",
      "loss_dino: 0.011033 [  840/ 1000]\n",
      "loss_dino: 0.011581 [  850/ 1000]\n",
      "loss_dino: 0.006948 [  860/ 1000]\n",
      "loss_dino: 0.018236 [  870/ 1000]\n",
      "loss_dino: 0.021927 [  880/ 1000]\n",
      "loss_dino: 0.012830 [  890/ 1000]\n",
      "loss_dino: 0.021624 [  900/ 1000]\n",
      "loss_dino: 0.009864 [  910/ 1000]\n",
      "loss_dino: 0.036434 [  920/ 1000]\n",
      "loss_dino: 0.014039 [  930/ 1000]\n",
      "loss_dino: 0.016058 [  940/ 1000]\n",
      "loss_dino: 0.013323 [  950/ 1000]\n",
      "loss_dino: 0.016702 [  960/ 1000]\n",
      "loss_dino: 0.033360 [  970/ 1000]\n",
      "loss_dino: 0.024810 [  980/ 1000]\n",
      "loss_dino: 0.032561 [  990/ 1000]\n",
      "loss_dino: 0.008284 [ 1000/ 1000]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,n_epochs+1):\n",
    "    for idx, batch in enumerate(train_loader_dino):\n",
    "        # prediction and loss\n",
    "        pred_dino = model_dino((batch[\"features\"]).to(device))\n",
    "        loss_dino = loss_fn(pred_dino,batch[\"label\"].type(torch.LongTensor).to(device))\n",
    "\n",
    "\n",
    "        # backpropagation\n",
    "        \n",
    "        loss_dino.backward()\n",
    "        optimizer_dino.step()\n",
    "        optimizer_dino.zero_grad()\n",
    "        \n",
    "    loss_dino, current = loss_dino.item(), idx*batch_size + len(batch[\"features\"])\n",
    "    if epoch%10 == 0 and epoch > 0:\n",
    "        print(f\"loss_dino: {loss_dino:>7f} [{epoch:>5d}/{n_epochs:>5d}]\")\n",
    "\n",
    "for epoch in range(1,n_epochs+1):\n",
    "    for idx, batch in enumerate(train_loader_clip):\n",
    "        \n",
    "        pred_clip = model_clip(batch[\"features\"].to(device))\n",
    "        loss_clip = loss_fn(pred_clip,batch[\"label\"].to(device))\n",
    "        \n",
    "        loss_clip.backward()\n",
    "        optimizer_clip.step()\n",
    "        optimizer_clip.zero_grad()\n",
    "    \n",
    "    loss_clip, current = loss_clip.item(), idx*batch_size + len(batch[\"features\"])\n",
    "    if epoch%10 == 0 and epoch > 0:\n",
    "        print(f\"loss_clip: {loss_clip:>7f} [{epoch:>5d}/{n_epochs:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy clip: 0.860185980796814\n",
      "accuracy dino: 0.7680767774581909\n"
     ]
    }
   ],
   "source": [
    "acc_clip = model_clip.get_model_accuracy_binary(test_data_clip.features,test_data_clip.label,binary_model=True,device=device)\n",
    "acc_dino = model_dino.get_model_accuracy_binary(test_data_dino.features,test_data_dino.label,binary_model=True,device=device)\n",
    "print(\"accuracy clip:\",acc_clip)\n",
    "print(\"accuracy dino:\",acc_dino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation of CLIP and DINOV2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clip_dino = SimpleDataset(features=torch.cat((train_data_clip.features,\n",
    "                                                    train_data_dino.features),dim=1),\n",
    "                                label=train_data_clip.label)\n",
    "\n",
    "test_clip_dino = SimpleDataset(features=torch.cat((test_data_clip.features.to(device),\n",
    "                                                   test_data_dino.features.to(device)),dim=1),\n",
    "                                label= test_data_clip.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3999, 1536])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clip_dino.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_clip: 0.406928 [   10/ 1000]\n",
      "loss_clip: 0.256964 [   20/ 1000]\n",
      "loss_clip: 0.213967 [   30/ 1000]\n",
      "loss_clip: 0.170856 [   40/ 1000]\n",
      "loss_clip: 0.105218 [   50/ 1000]\n",
      "loss_clip: 0.038156 [   60/ 1000]\n",
      "loss_clip: 0.093853 [   70/ 1000]\n",
      "loss_clip: 0.053000 [   80/ 1000]\n",
      "loss_clip: 0.047475 [   90/ 1000]\n",
      "loss_clip: 0.020674 [  100/ 1000]\n",
      "loss_clip: 0.056921 [  110/ 1000]\n",
      "loss_clip: 0.037268 [  120/ 1000]\n",
      "loss_clip: 0.032698 [  130/ 1000]\n",
      "loss_clip: 0.050717 [  140/ 1000]\n",
      "loss_clip: 0.028283 [  150/ 1000]\n",
      "loss_clip: 0.030035 [  160/ 1000]\n",
      "loss_clip: 0.045557 [  170/ 1000]\n",
      "loss_clip: 0.016609 [  180/ 1000]\n",
      "loss_clip: 0.031243 [  190/ 1000]\n",
      "loss_clip: 0.027374 [  200/ 1000]\n",
      "loss_clip: 0.011715 [  210/ 1000]\n",
      "loss_clip: 0.015760 [  220/ 1000]\n",
      "loss_clip: 0.010196 [  230/ 1000]\n",
      "loss_clip: 0.020012 [  240/ 1000]\n",
      "loss_clip: 0.012137 [  250/ 1000]\n",
      "loss_clip: 0.009863 [  260/ 1000]\n",
      "loss_clip: 0.019553 [  270/ 1000]\n",
      "loss_clip: 0.005883 [  280/ 1000]\n",
      "loss_clip: 0.014183 [  290/ 1000]\n",
      "loss_clip: 0.008728 [  300/ 1000]\n",
      "loss_clip: 0.014037 [  310/ 1000]\n",
      "loss_clip: 0.008685 [  320/ 1000]\n",
      "loss_clip: 0.007125 [  330/ 1000]\n",
      "loss_clip: 0.015109 [  340/ 1000]\n",
      "loss_clip: 0.010541 [  350/ 1000]\n",
      "loss_clip: 0.003729 [  360/ 1000]\n",
      "loss_clip: 0.009370 [  370/ 1000]\n",
      "loss_clip: 0.010959 [  380/ 1000]\n",
      "loss_clip: 0.008411 [  390/ 1000]\n",
      "loss_clip: 0.003362 [  400/ 1000]\n",
      "loss_clip: 0.006828 [  410/ 1000]\n",
      "loss_clip: 0.005742 [  420/ 1000]\n",
      "loss_clip: 0.006431 [  430/ 1000]\n",
      "loss_clip: 0.004037 [  440/ 1000]\n",
      "loss_clip: 0.004765 [  450/ 1000]\n",
      "loss_clip: 0.006099 [  460/ 1000]\n",
      "loss_clip: 0.009266 [  470/ 1000]\n",
      "loss_clip: 0.002385 [  480/ 1000]\n",
      "loss_clip: 0.004036 [  490/ 1000]\n",
      "loss_clip: 0.006364 [  500/ 1000]\n",
      "loss_clip: 0.005946 [  510/ 1000]\n",
      "loss_clip: 0.006740 [  520/ 1000]\n",
      "loss_clip: 0.004453 [  530/ 1000]\n",
      "loss_clip: 0.003728 [  540/ 1000]\n",
      "loss_clip: 0.004942 [  550/ 1000]\n",
      "loss_clip: 0.005274 [  560/ 1000]\n",
      "loss_clip: 0.006071 [  570/ 1000]\n",
      "loss_clip: 0.004056 [  580/ 1000]\n",
      "loss_clip: 0.002296 [  590/ 1000]\n",
      "loss_clip: 0.006442 [  600/ 1000]\n",
      "loss_clip: 0.003580 [  610/ 1000]\n",
      "loss_clip: 0.003441 [  620/ 1000]\n",
      "loss_clip: 0.003991 [  630/ 1000]\n",
      "loss_clip: 0.002282 [  640/ 1000]\n",
      "loss_clip: 0.004159 [  650/ 1000]\n",
      "loss_clip: 0.001820 [  660/ 1000]\n",
      "loss_clip: 0.003357 [  670/ 1000]\n",
      "loss_clip: 0.003199 [  680/ 1000]\n",
      "loss_clip: 0.003697 [  690/ 1000]\n",
      "loss_clip: 0.002278 [  700/ 1000]\n",
      "loss_clip: 0.001391 [  710/ 1000]\n",
      "loss_clip: 0.003093 [  720/ 1000]\n",
      "loss_clip: 0.002804 [  730/ 1000]\n",
      "loss_clip: 0.002043 [  740/ 1000]\n",
      "loss_clip: 0.002016 [  750/ 1000]\n",
      "loss_clip: 0.002949 [  760/ 1000]\n",
      "loss_clip: 0.002501 [  770/ 1000]\n",
      "loss_clip: 0.002463 [  780/ 1000]\n",
      "loss_clip: 0.001622 [  790/ 1000]\n",
      "loss_clip: 0.002840 [  800/ 1000]\n",
      "loss_clip: 0.002577 [  810/ 1000]\n",
      "loss_clip: 0.002165 [  820/ 1000]\n",
      "loss_clip: 0.003022 [  830/ 1000]\n",
      "loss_clip: 0.002318 [  840/ 1000]\n",
      "loss_clip: 0.003151 [  850/ 1000]\n",
      "loss_clip: 0.002902 [  860/ 1000]\n",
      "loss_clip: 0.002802 [  870/ 1000]\n",
      "loss_clip: 0.002371 [  880/ 1000]\n",
      "loss_clip: 0.001703 [  890/ 1000]\n",
      "loss_clip: 0.003154 [  900/ 1000]\n",
      "loss_clip: 0.002075 [  910/ 1000]\n",
      "loss_clip: 0.001421 [  920/ 1000]\n",
      "loss_clip: 0.001429 [  930/ 1000]\n",
      "loss_clip: 0.001549 [  940/ 1000]\n",
      "loss_clip: 0.002043 [  950/ 1000]\n",
      "loss_clip: 0.002799 [  960/ 1000]\n",
      "loss_clip: 0.001904 [  970/ 1000]\n",
      "loss_clip: 0.001933 [  980/ 1000]\n",
      "loss_clip: 0.002260 [  990/ 1000]\n",
      "loss_clip: 0.002406 [ 1000/ 1000]\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "model = MultiClassClassifier(n_features=CLIP_FEATURE_DIM+DINO_FEATURE_DIM,n_classes=2).to(device)\n",
    "model.train()\n",
    "\n",
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "n_epochs = 1000\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "rng = rng = torch.Generator().manual_seed(SEED)\n",
    "train_loader = DataLoader(train_clip_dino,batch_size=batch_size,shuffle=True,generator=rng)\n",
    "\n",
    "for epoch in range(1,n_epochs+1):\n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        \n",
    "        pred = model(batch[\"features\"].to(device))\n",
    "        loss = loss_fn(pred,batch[\"label\"].to(device))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    loss, current = loss.item(), idx*batch_size + len(batch[\"features\"])\n",
    "    if epoch%10 == 0 and epoch > 0:\n",
    "        print(f\"loss_clip: {loss:>7f} [{epoch:>5d}/{n_epochs:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8955895304679871"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_model_accuracy_binary(test_clip_dino.features,test_clip_dino.label,device=device,binary_model=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
