{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lsaland/micromamba/envs/clip/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/lsaland/micromamba/envs/clip/lib/python3.11/site-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
      "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:02<00:00,  2.93it/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../model\")\n",
    "sys.path.append(\"../tools\")\n",
    "from dataset import *\n",
    "from constants import PATH_TO_DATA, PATH_TO_DATA4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_per_gen = 10\n",
    "data = DeepFakeDataset(PATH_TO_DATA,\n",
    "                       img_per_gen=img_per_gen,\n",
    "                       balance_real_fake=True,\n",
    "                       device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_per_gen = 1000\n",
    "data = DeepFakeTest(\"/data3/AID_TEST/\",\n",
    "                    load_from_disk=False,\n",
    "                    img_per_gen=img_per_gen,\n",
    "                    balance_real_fake=True,\n",
    "                    device=\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.save(PATH_TO_DATA4 + f\"df_test_{len(data)}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.bincount(data.gen.int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../tools\")\n",
    "from constants import INT_TO_GEN\n",
    "import numpy as np\n",
    "i = np.random.randint(0,len(data))\n",
    "print(data.gen_original_name[i])\n",
    "print(INT_TO_GEN[data.gen[i].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1090/1090 [1:13:43<00:00,  4.06s/it]\n",
      "100%|██████████| 1090/1090 [08:28<00:00,  2.14it/s]\n"
     ]
    }
   ],
   "source": [
    "data = RealFakePairs(path_to_real_imgs=\"/data3/AID_pairs_orig_gen/originals/\",\n",
    "                     path_to_fake_imgs=\"/data3/AID_pairs_orig_gen/generated/\",\n",
    "                     img_per_class=1090,\n",
    "                     device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.save(\"/data4/saland/data/real_fake_pairs_1090.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DoubleCLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/home/lsaland/micromamba/envs/clip/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608853085/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "100%|██████████| 1000/1000 [6:12:47<00:00, 22.37s/it] \n",
      "100%|██████████| 1000/1000 [5:50:17<00:00, 21.02s/it] \n"
     ]
    }
   ],
   "source": [
    "data = DoubleCLIP(load_from_disk=False,\n",
    "                  path_to_Blip_model_cache=\"/data4/saland/cache\",\n",
    "                  path_to_imgs=\"/data3/AID_pairs_orig_gen/\",\n",
    "                  imgs_per_label=1000,\n",
    "                  num_inference_steps=100,\n",
    "                  device=\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.save(f\"/data4/saland/data/Double_CLIP_{len(data)}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.51it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data2 = DoubleCLIP(load_from_disk=True,path_to_datset=\"/data4/saland/data/Double_CLIP_2000.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.67it/s]\n",
      "100%|██████████| 73/73 [00:32<00:00,  2.28it/s]\n",
      "100%|██████████| 100/100 [00:03<00:00, 30.47it/s]\n"
     ]
    }
   ],
   "source": [
    "data = LongCaption(device=\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.save(\"/data4/saland/data/LongCaption.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
