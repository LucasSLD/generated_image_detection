{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open_clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "model, _, preprocess = open_clip.create_model_and_transforms('hf-hub:laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',device=\"cuda\")\n",
    "tokenizer = open_clip.get_tokenizer('hf-hub:laion/CLIP-ViT-bigG-14-laion2B-39B-b160k')\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELSA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"../../img/cat.png\")\n",
    "\n",
    "image = preprocess(img).unsqueeze(0).cuda()\n",
    "text = tokenizer([\"a diagram\", \"a dog\", \"a cat\"]).cuda()\n",
    "\n",
    "display(img)\n",
    "\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "print(\"Label probs:\", text_probs)  # prints: [[1., 0., 0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"../../img/cat.jpg\")\n",
    "\n",
    "image = preprocess(img).unsqueeze(0).cuda()\n",
    "text = tokenizer([\"a diagram\", \"a dog\", \"a cat\"]).cuda()\n",
    "\n",
    "display(img)\n",
    "\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "print(\"Label probs:\", text_probs)  # prints: [[1., 0., 0.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"elsaEU/ELSA_D3\",split=\"train\",streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the dataset in pytorch format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in dataset:\n",
    "    img = preprocess(e[\"image_gen0\"]).unsqueeze(0).cuda()\n",
    "    img_features = model.encode_image(img)\n",
    "    display(img_features.shape)\n",
    "    display(img_features.flatten().shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset.with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of one sample from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import sys\n",
    "sys.path.append(\"../tools/\")\n",
    "from utils import plot_tensor\n",
    "\n",
    "for e in ds:\n",
    "    display(e)\n",
    "\n",
    "    # Real image\n",
    "    plt.imshow(np.asarray(Image.open(requests.get(e[\"url\"], stream=True).raw)))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(\"Real image\")\n",
    "    plt.show()\n",
    "\n",
    "    # Generated images\n",
    "    fig, axs = plt.subplots(2,2)\n",
    "    base_name = \"image_gen\"\n",
    "    for i in range(4):\n",
    "        fig.sca(axs.flatten()[i])\n",
    "        plot_tensor(e[\"image_gen\" + str(i)])\n",
    "    plt.suptitle(\"Generated images\")\n",
    "    plt.tight_layout()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
